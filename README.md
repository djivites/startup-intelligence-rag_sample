

# ğŸš€ Startup Intelligence RAG System

**AI-Powered Funding & Startup Intelligence Platform**

---

## ğŸ“Œ Overview

**Startup â€“ Funder Intelligence Hub** is a **Retrieval-Augmented Generation (RAG)** based AI system designed to help founders, investors, and analysts discover reliable startup intelligence from real-world sources.

The platform automatically **collects, processes, understands, and retrieves startup-related information** from news articles, blogs, and reports, enabling users to ask natural-language questions and receive **fact-grounded, citation-backed insights**.

This system is built with **LangChain + Ollama + ChromaDB**,as of now ollama is implemented further we will be changing from ollama to gemini for better results, and supports **multilingual queries**, **context-aware reasoning**, and **structured information extraction**.

---


---

## ğŸ¯ Key Objectives

* Reduce manual research time for startup and investment intelligence
* Provide verified, citation-backed answers using trusted data sources
* Enable intelligent **investorâ€“startup matching** through contextual understanding
* Support **multilingual and cross-lingual queries** for wider accessibility
* Minimize hallucinations using a **grounded Retrieval-Augmented Generation (RAG)** architecture
* Enable **document upload and intelligent analysis** (pitch decks, reports, policies) for structured insight extraction
* Provide an **interactive questionâ€“answer engine** that dynamically refines responses based on user intent
* Support **translation-aware retrieval**, allowing users to query in one language and retrieve insights from documents in another
* Build a scalable foundation for future intelligent features such as reasoning, recommendation, and trend detection

---

---
### ğŸ§  System Architecture
![System Architecture](Photos/System architecture.png)

```

```

---

## ğŸ§© Features

### âœ… Implemented

* ğŸ“° Automated startup news ingestion (TechCrunch, YourStory)
* ğŸ§  LLM-based information extraction
* ğŸ“¦ Structured storage (JSON + SQLite)
* ğŸ” Semantic search using ChromaDB
* ğŸ’¬ Conversational RAG interface
* ğŸ§¾ Source-cited responses
* ğŸ—‚ Metadata-based filtering

### ğŸš§ In Progress

* ğŸŒ Multilingual translation support
* ğŸ“„ Document upload (PDF / PPT / DOCX)
* ğŸ” Duplicate content detection for other three sources(blogs,vc thesis,policy pdfs)
* ğŸ§© Intelligent follow-up questioning
* ğŸ¨ React + Tailwind UI

---

## ğŸ—‚ï¸ Project Structure

```
startup-intelligence-rag/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Raw scraped articles
â”‚   â”œâ”€â”€ processed/          # Structured JSON outputs
â”‚   â”œâ”€â”€ metadata/           # SQLite metadata DB
â”‚
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ fetch_news.py       # RSS-based news ingestion
â”‚   â”œâ”€â”€ fetch_tech_blogs.py
â”‚   â”œâ”€â”€ fetch_vc.py
â”‚
â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ llm_processing.py   # LLM-based information extraction
â”‚   â”œâ”€â”€ process_articles.py
â”‚
â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ rag.py              # Vector DB creation
â”‚   â”œâ”€â”€ rag_app.py          # Streamlit RAG interface
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Tech Stack

| Component     | Technology           |
| ------------- | -------------------- |
| LLM           | LLaMA 3 (via Ollama) |
| Embeddings    | Ollama Embeddings    |
| Vector DB     | ChromaDB             |
| Backend       | Python               |
| UI            | Streamlit            |
| Storage       | SQLite               |
| Parsing       | BeautifulSoup        |
| RAG Framework | LangChain            |

---
In Futher implentation we will be using Gemini instead of ollama for better results.

## ğŸ§ª How It Works (Pipeline)

1. **News Ingestion**

   * RSS feeds are scraped
   * Articles cleaned and stored

2. **LLM Processing**

   * Extracts:

     * Summary
     * Key facts
     * Funding info
     * Metadata

3. **Vectorization**

   * Text embedded using LLaMA
   * Stored in ChromaDB

4. **Retrieval**

   * Semantic search retrieves relevant chunks

5. **Generation**

   * LLM generates grounded responses with evidence

---

## â–¶ï¸ How to Run

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Start Ollama

```bash
ollama run llama3
```

### 3. Run Ingestion

```bash
python ingestion/fetch_news.py
python processing/process_articles.py
```

### 4. Build Vector Database

```bash
python retrieval/rag.py
```

### 5. Launch Application

```bash
streamlit run retrieval/rag_app.py
```

---

## ğŸ§  Example Queries

* *â€œWhich startups recently raised Series A funding in India?â€*
* *â€œShow startups related to AI healthcare funding.â€*
* *â€œWhich investors are active in fintech?â€*

---

## ğŸ›£ï¸ Roadmap

| Feature              | Status |
| -------------------- | ------ |
| News ingestion       | âœ…     |
| RAG pipeline         | âœ…     |
| Chat history         | âœ…     |
| Multilingual support | ğŸ”„     |
| Document upload      | ğŸ”„     |
| UI Dashboard         | ğŸ”„     |
| Duplicate detection  | ğŸ”œ     |
| Investor matching    | ğŸ”œ     |

## ğŸ“¸ Project Screenshots

### ğŸ  Home / Chat Interface
![Chat Interface](Photos/opimage1.png)

### ğŸ” Chat history
![Chat history](Photos/opimage2.png)




